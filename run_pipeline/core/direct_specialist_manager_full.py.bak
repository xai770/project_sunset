#!/usr/bin/env python3
"""
Direct Specialist Manager - Phase 3 Architecture Optimization
============================================================

This module provides direct specialist integration patterns to replace
the complex LLM Client abstraction layers, achieving 40% architecture
simplification as outlined in ARCHITECTURE_REVIEW_JUNE_2025.md.

Key Benefits:
- Direct specialist instantiation and usage
- Elimination of abstraction overhead
- Simplified error handling and debugging
- Enhanced performance through direct access
"""

from typing import Dict, Any, Optional, List, Union
import logging
import sys
import time
from dataclasses import dataclass

# Configure logging
logger = logging.getLogger(__name__)

# LLM Factory Direct Integration - no abstraction layers
try:
    sys.path.insert(0, '/home/xai/Documents/llm_factory')
    from llm_factory.modules.quality_validation.specialists_versioned.registry import SpecialistRegistry
    from llm_factory.core.types import ModuleConfig
    from llm_factory.core.ollama_client import OllamaClient
    LLM_FACTORY_AVAILABLE = True
    logger.info("✅ Direct LLM Factory access available")
except ImportError as e:
    LLM_FACTORY_AVAILABLE = False
    logger.warning(f"⚠️ LLM Factory not available for direct access: {e}")

@dataclass
class SpecialistResult:
    """Standardized result format for all specialist operations"""
    success: bool
    result: Any
    specialist_used: str
    execution_time: float
    quality_score: Optional[float] = None
    error: Optional[str] = None

class DirectJobMatchingSpecialists:
    """
    Direct job matching specialists - no abstraction layers
    
    Phase 3 Architecture: Simplified specialist access without wrapper classes
    """
    
    def __init__(self, model: str = "llama3.2:latest"):
        self.model = model
        self.registry = None
        self.client = None
        self._init_direct_access()
    
    def _init_direct_access(self):
        """Initialize direct specialist access"""
        if not LLM_FACTORY_AVAILABLE:
            logger.info("LLM Factory not available - fallback mode")
            return
        
        try:
            self.client = OllamaClient()  # type: ignore
            self.registry = SpecialistRegistry()  # type: ignore
            logger.info("✅ Direct specialist access initialized")
        except Exception as e:
            logger.error(f"❌ Failed to initialize direct specialist access: {e}")
            self.client = None
            self.registry = None
    
    def evaluate_job_fitness(self, cv_data: Dict[str, Any], job_data: Dict[str, Any]) -> SpecialistResult:
        """
        Direct job fitness evaluation - Phase 3 simplified architecture
        """
        if not self.registry or not self.client:
            return SpecialistResult(
                success=False, 
                result=None,
                specialist_used="none",
                execution_time=0.0,
                error="Direct specialist access not available"
            )
        
        try:
            start_time = time.time()
            
            # Direct specialist configuration - no wrapper classes
            config = ModuleConfig(  # type: ignore
                models=[self.model],
                conservative_bias=True,
                quality_threshold=8.0,
                ollama_client=self.client
            )
            
            # Load specialist directly from registry
            specialist = self.registry.load_specialist("job_fitness_evaluator", config)  # type: ignore
            
            # Direct input preparation
            input_data = {
                "job_posting": {
                    "description": job_data.get("description", ""),
                    "title": "Job Position",
                    "requirements": []
                },
                "candidate_profile": {
                    "cv_content": cv_data.get("text", ""),
                    "name": "Candidate",
                    "skills": [],
                    "experience": ""
                }
            }
            
            # Direct specialist call
            result = specialist.process(input_data)
            execution_time = time.time() - start_time
            
            if result.success:
                return SpecialistResult(
                    success=True,
                    result=result.data,
                    specialist_used="job_fitness_evaluator",
                    execution_time=execution_time,
                    quality_score=getattr(result, 'quality_score', None)
                )
            else:
                return SpecialistResult(
                    success=False,
                    result=None,
                    specialist_used="job_fitness_evaluator", 
                    execution_time=execution_time,
                    error="Specialist processing failed"
                )
                
        except Exception as e:
            logger.error(f"❌ Direct fitness assessment failed: {e}")
            return SpecialistResult(
                success=False,
                result=None,
                specialist_used="job_fitness_evaluator",
                execution_time=0.0,
                error=str(e)
            )


def get_job_matching_specialists(model: str = "llama3.2:latest") -> DirectJobMatchingSpecialists:
    """
    Get direct access to job matching specialists - Phase 3 Architecture
    
    No abstraction layers, no wrapper classes - direct specialist access only.
    Achieves 40% architecture simplification by eliminating:
    - LLMFactoryJobMatcher wrapper
    - LLMFactoryEnhancer wrapper  
    - Complex abstraction hierarchies
    
    Args:
        model: LLM model to use
        
    Returns:
        Direct specialist access manager
    """
    return DirectJobMatchingSpecialists(model)


def is_direct_specialists_available() -> bool:
    """Check if direct specialist access is available"""
    return LLM_FACTORY_AVAILABLE


def get_specialist_status() -> Dict[str, Any]:
    """Get status of direct specialist access"""
    if not LLM_FACTORY_AVAILABLE:
        return {
            "available": False,
            "error": "LLM Factory not available",
            "phase": "fallback_only"
        }
    
    try:
        specialists = get_job_matching_specialists()
        return {
            "available": True,
            "phase": "direct_access_v3",
            "architecture": "simplified_no_abstractions",
            "ready": specialists.registry is not None
        }
    except Exception as e:
        return {
            "available": False,
            "error": str(e),
            "phase": "fallback_only"
        }


class DirectSpecialistManager:
    """
    Phase 3 Architecture: Direct Specialist Manager
    
    Main entry point for simplified specialist access without abstraction layers.
    Replaces complex LLM Client hierarchies with direct specialist integration.
    """
    
    def __init__(self, model: str = "llama3.2:latest"):
        self.model = model
        self.job_matching = get_job_matching_specialists(model)
        
    def get_job_matching_specialists(self) -> DirectJobMatchingSpecialists:
        """Get direct job matching specialist access"""
        return self.job_matching
        
    def is_available(self) -> bool:
        """Check if direct specialist access is available"""
        return is_direct_specialists_available()
        
    def get_status(self) -> Dict[str, Any]:
        """Get comprehensive status of specialist access"""
        return get_specialist_status()


def get_feedback_specialists(model: str = "llama3.2:latest") -> DirectJobMatchingSpecialists:
    """
    Get direct access to feedback analysis specialists - Phase 3 Architecture
    
    Simplified feedback specialist access without abstraction layers.
    Uses the same specialist infrastructure as job matching.
    
    Args:
        model: LLM model to use
        
    Returns:
        Direct specialist access for feedback analysis
    """
    return DirectJobMatchingSpecialists(model)
